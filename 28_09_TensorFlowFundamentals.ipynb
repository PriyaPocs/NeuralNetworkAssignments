{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ada419-6779-4a59-89af-3744bc12b5a1",
   "metadata": {},
   "source": [
    "Part 1: Theoretical Questionk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3f3a8-21f2-4bc5-8545-2872642f5692",
   "metadata": {},
   "source": [
    "1.What are the different data structures used in Tensorflow?. Give some examples?\n",
    "\n",
    "Answer(1):\n",
    "\n",
    "TensorFlow, a popular deep learning framework, provides various data structures to work with tensors and datasets. Here are some of the key data structures used in TensorFlow, along with examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd4ac4b-0b6f-4daf-a4cb-bc75b4175e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.1-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.9/181.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting urllib3>=2.0.5\n",
      "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests, pyasn1-modules, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.13\n",
      "    Uninstalling urllib3-1.26.13:\n",
      "      Successfully uninstalled urllib3-1.26.13\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.58.0 keras-2.14.0 libclang-16.0.6 markdown-3.4.4 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 urllib3-2.0.5 werkzeug-2.3.7 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4f9a13-768e-43da-b89d-760df66381be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar = 5\n",
      "vector = [1 2 3]\n",
      "matrix = [[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow, a popular deep learning framework, provides various data structures to work with tensors and datasets. Here are some of the key data structures used in TensorFlow, along with examples:\n",
    "\n",
    "# 1. **Tensor**: Tensors are multi-dimensional arrays that represent the fundamental building blocks of data in TensorFlow. Tensors can be scalars (0-D), vectors (1-D), matrices (2-D), or higher-dimensional arrays.\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "scalar = tf.constant(5)        # 0-D tensor (scalar)\n",
    "vector = tf.constant([1, 2, 3]) # 1-D tensor (vector)\n",
    "matrix = tf.constant([[1, 2], [3, 4]]) # 2-D tensor (matrix)\n",
    "\n",
    "\n",
    "print(f\"scalar = {scalar}\")\n",
    "print(f\"vector = {vector}\")\n",
    "print(f\"matrix = {matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd4f63b-2c61-424f-b73a-16954e82e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight = <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0.5, 1. ], dtype=float32)> \n",
      "\n",
      "dataset = <_BatchDataset element_spec=(TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))> \n",
      "\n",
      "sparse_tensor = SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([3. 4.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 3], shape=(2,), dtype=int64)) \n",
      "\n",
      "ragged_tensor = <tf.RaggedTensor [[1, 2], [3, 4, 5], [6]]> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. **Variable**: Variables are used to store and update trainable parameters (weights and biases) in machine learning models.\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "weight = tf.Variable([0.5, 1.0])\n",
    "print(f\"weight = {weight} \\n\")\n",
    "\n",
    "\n",
    "# 3. **Placeholder (deprecated)**: Placeholders were used in older versions of TensorFlow for feeding data into a computational graph. However, they have been deprecated in favor of the `tf.data` API and `tf.function`.\n",
    "\n",
    "# x = tf.compat.v1.placeholder(tf.float32, shape=(None, 3))\n",
    "# print(f\"x = {x}\")\n",
    "\n",
    "# 4.Dataset: The tf.data.Dataset API is used for efficient data input pipelines. It allows you to create, transform, and batch datasets.\n",
    "\n",
    "data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]\n",
    "labels = [0, 1, 0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.shuffle(buffer_size=100).batch(32)\n",
    "print(f\"dataset = {dataset} \\n\")\n",
    "\n",
    "\n",
    "# 5. **SparseTensor**: Sparse tensors are used to represent sparse data efficiently, such as sparse matrices or sparse feature vectors.\n",
    "\n",
    "\n",
    "# Define the indices as int64\n",
    "indices = tf.constant([[0, 1], [1, 2]], dtype=tf.int64)\n",
    "# Define values\n",
    "values = tf.constant([3.0, 4.0])\n",
    "# Define the dense_shape with dtype int64\n",
    "shape = tf.constant([3, 3], dtype=tf.int64)\n",
    "# Create a SparseTensor\n",
    "sparse_tensor = tf.SparseTensor(indices, values, shape)\n",
    "\n",
    "print(f\"sparse_tensor = {sparse_tensor} \\n\")\n",
    "\n",
    "\n",
    "# 6. **RaggedTensor**: Ragged tensors are used to represent sequences of varying lengths, which are common in natural language processing tasks.\n",
    "\n",
    "\n",
    "ragged_tensor = tf.ragged.constant([[1, 2], [3, 4, 5], [6]])\n",
    "print(f\"ragged_tensor = {ragged_tensor} \\n\")\n",
    "\n",
    "# These are some of the fundamental data structures in TensorFlow. Depending on the specific use case, you may encounter other specialized data structures and abstractions, but these cover the basics for most deep learning tasks. Note that TensorFlow's API evolves over time, so it's essential to refer to the official documentation for the latest information and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efdfe0-50ad-4741-b907-e1d0e87356bc",
   "metadata": {},
   "source": [
    "2. How does the TensorFlow constant differ from a TensorFlow variable? Explain with an example?\n",
    "\n",
    "Answer(2):\n",
    "In TensorFlow, constants and variables are two different types of tensors used to represent data, but they have distinct characteristics and use cases. Here's how they differ:\n",
    "\n",
    "1. **TensorFlow Constants**:\n",
    "\n",
    "   - **Immutable**: Constants are immutable, meaning their values cannot be changed once they are defined. They hold a fixed value throughout the execution of a TensorFlow graph.\n",
    "   - **Typically for Data**: Constants are often used to represent fixed data values that do not change during training, such as hyperparameters, model configurations, or fixed input data.\n",
    "   - **Memory Efficiency**: Constants are memory-efficient because they are stored once and shared across the graph.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   import tensorflow as tf\n",
    "\n",
    "   # Define a constant tensor\n",
    "   constant_tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "\n",
    "   # Attempting to assign a new value to a constant will result in an error\n",
    "   # constant_tensor.assign([4.0, 5.0, 6.0])  # This will raise an error\n",
    "   ```\n",
    "\n",
    "2. **TensorFlow Variables**:\n",
    "\n",
    "   - **Mutable**: Variables are mutable, allowing their values to be changed during the execution of a TensorFlow graph. They are typically used to store and update the learnable parameters of machine learning models, such as weights and biases.\n",
    "   - **Training Parameters**: Variables are commonly used for parameters that need to be optimized during training, and they can be updated by optimization algorithms like gradient descent.\n",
    "   - **Initialization Required**: Variables require an explicit initialization step before they can be used in a session. This initialization sets their initial values.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   import tensorflow as tf\n",
    "\n",
    "   # Define a variable tensor\n",
    "   initial_values = [1.0, 2.0, 3.0]\n",
    "   variable_tensor = tf.Variable(initial_values)\n",
    "\n",
    "   # Variables can be updated using assign operations\n",
    "   variable_tensor.assign([4.0, 5.0, 6.0])\n",
    "\n",
    "   # Variables need to be explicitly initialized before use in a session\n",
    "   init = tf.compat.v1.global_variables_initializer()  # Initialization operation\n",
    "   with tf.compat.v1.Session() as sess:\n",
    "       sess.run(init)  # Initialize variables\n",
    "       result = sess.run(variable_tensor)\n",
    "   ```\n",
    "\n",
    "In summary, constants are used for fixed, unchanging values in TensorFlow, while variables are used for mutable values that need to be optimized during training. Variables require explicit initialization and can be updated, while constants remain fixed throughout the execution of a TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05c342-94c3-4c77-9a39-19d0967f355e",
   "metadata": {},
   "source": [
    "3. Describe the process of matrix addition, multiplication, and element-wise operations in TensorFlow.\n",
    "\n",
    "Answer(3):\n",
    "\n",
    "These are the basic operations for matrix addition, multiplication, and element-wise operations in TensorFlow as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f95910-55b0-4493-96b0-2fd06be59117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Addition:\n",
      "[[ 6  8]\n",
      " [10 12]]\n",
      "\n",
      "Matrix Multiplication:\n",
      "[[19 22]\n",
      " [43 50]]\n",
      "\n",
      "Element-wise Multiplication:\n",
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define two matrices\n",
    "matrix_a = tf.constant([[1, 2], [3, 4]])\n",
    "matrix_b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform matrix addition\n",
    "addition_result = tf.add(matrix_a, matrix_b)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "multiplication_result = tf.matmul(matrix_a, matrix_b)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "element_wise_result = tf.multiply(matrix_a, matrix_b)\n",
    "\n",
    "print(\"Matrix Addition:\")\n",
    "print(addition_result.numpy())\n",
    "\n",
    "print(\"\\nMatrix Multiplication:\")\n",
    "print(multiplication_result.numpy())\n",
    "\n",
    "print(\"\\nElement-wise Multiplication:\")\n",
    "print(element_wise_result.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bed946-79e5-4832-bb2d-f3e810fc1be4",
   "metadata": {},
   "source": [
    "Part 2: Practical Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4653a2b-82fb-4d4e-8719-605a36769d7e",
   "metadata": {},
   "source": [
    "Task 1: Creating and Manipulating Matrice\n",
    "\n",
    "1. Create a normal matrix A with dimensions 3x3, using TensorFlow's random_normal function. Display the values of matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bbd5afd-e293-4acc-9aee-deb766b391fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[-0.48184893 -0.14388245 -0.1955412 ]\n",
      " [-0.6539595  -0.53080565  0.45206136]\n",
      " [ 0.63473976  0.07630948  1.7150594 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a 3x3 matrix with random values from a normal distribution\n",
    "matrix_A = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Display the values of the matrix\n",
    "print(\"Matrix A:\")\n",
    "print(matrix_A.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09235daf-f89f-4d8c-8540-7aeaf3b54447",
   "metadata": {},
   "source": [
    "2. Create a Gaussian matrix B with dimensions 4x4, using TensorFlow's truncated_normal function. Display the values of matrix B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f249d357-7c60-4894-88f7-97a4ed279032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix B:\n",
      "[[-0.549787    0.6540923  -0.66147316 -0.6913391 ]\n",
      " [-0.23713088  0.85479295  1.4096663  -0.08138409]\n",
      " [ 1.358484   -0.586029   -0.8784891  -0.4593105 ]\n",
      " [ 0.40769148  0.08256792 -0.8812569   0.4299257 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a 4x4 matrix with random values from a truncated normal distribution\n",
    "matrix_B = tf.random.truncated_normal(shape=(4, 4), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Display the values of the matrix\n",
    "print(\"Matrix B:\")\n",
    "print(matrix_B.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb3444-6f01-4763-bd64-4644dbb7b438",
   "metadata": {},
   "source": [
    "3. Create a matrix C with dimensions 2x2, where the values are drawn from a normal distribution with a mean of 3 and a standard deviation of 0.5, using TensorFlow's random.normal function. Display the values of matrix C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e111fd00-2c0b-4e52-8eb0-bde0c3648eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix C:\n",
      "[[2.8154814 2.945449 ]\n",
      " [3.766169  3.2527046]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the mean and standard deviation\n",
    "mean = 3.0\n",
    "stddev = 0.5\n",
    "\n",
    "# Create a 2x2 matrix with random values from a normal distribution\n",
    "matrix_C = tf.random.normal(shape=(2, 2), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "\n",
    "# Display the values of matrix C\n",
    "print(\"Matrix C:\")\n",
    "print(matrix_C.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeee319-0631-4f7b-a53f-9ee5d0b1ff22",
   "metadata": {},
   "source": [
    "4. Perform matrix addition between matrix A and matrix B, and store the result in matrix D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106e815a-a0d7-4b55-9a47-ddb79487bd05",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,3] vs. [4,4] [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m matrix_B \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m), mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, stddev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Perform matrix addition between A and B\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m matrix_D \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the result matrix D\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix D (Result of A + B):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,3] vs. [4,4] [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have matrix A and matrix B as previously defined\n",
    "matrix_A = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "matrix_B = tf.random.truncated_normal(shape=(4, 4), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Perform matrix addition between A and B\n",
    "matrix_D = tf.add(matrix_A, matrix_B)\n",
    "\n",
    "# Display the result matrix D\n",
    "print(\"Matrix D (Result of A + B):\")\n",
    "print(matrix_D.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "765c8e17-d8b1-4784-aa6b-697842360f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix D (Result of A + B):\n",
      "[[-3.7134051  -0.34727752 -0.23913056]\n",
      " [ 0.85652435 -0.02615541 -0.62503004]\n",
      " [-0.19288328  0.27122486 -1.9390346 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a 3x3 matrix A with random values\n",
    "matrix_A = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Create a 3x3 matrix B with random values\n",
    "matrix_B = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Perform matrix addition between A and B\n",
    "matrix_D = tf.add(matrix_A, matrix_B)\n",
    "\n",
    "# Display the result matrix D\n",
    "print(\"Matrix D (Result of A + B):\")\n",
    "print(matrix_D.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76797099-cf78-4d1d-90f2-65d9b86cbb7d",
   "metadata": {},
   "source": [
    "5. Perform matrix multiplication between matrix C and matrix D, and store the result in matrix E.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c76cfe10-1c6f-4e3d-adf7-332bc3e5cc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix D (Result of A + B):\n",
      "[[-0.63633204  2.106967    0.5883774 ]\n",
      " [ 0.5391721  -0.5446354  -1.0650203 ]\n",
      " [-0.28847873 -1.4829566  -0.3546988 ]]\n",
      "Matrix C:\n",
      "[[3.3812654 3.2255747 3.6240485]\n",
      " [3.9899054 2.7906199 2.8738177]\n",
      " [3.5540957 3.3152707 2.554994 ]]\n",
      "Matrix E (Result of C * D):\n",
      "[[-1.4579285  -0.00685415 -2.7312882 ]\n",
      " [-1.8633156   2.6249816  -1.6438364 ]\n",
      " [-1.211145    1.8938034  -2.3459344 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a 3x3 matrix A with random values\n",
    "matrix_A = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Create a 3x3 matrix B with random values\n",
    "matrix_B = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Perform matrix addition between A and B\n",
    "matrix_D = tf.add(matrix_A, matrix_B)\n",
    "\n",
    "# Display the result matrix D\n",
    "print(\"Matrix D (Result of A + B):\")\n",
    "print(matrix_D.numpy())\n",
    "\n",
    "# Create matrix C with dimensions 2x3\n",
    "mean_C = 3.0\n",
    "stddev_C = 0.5\n",
    "matrix_C = tf.random.normal(shape=(3, 3), mean=mean_C, stddev=stddev_C, dtype=tf.float32)\n",
    "\n",
    "# Display the values of matrix C\n",
    "print(\"Matrix C:\")\n",
    "print(matrix_C.numpy())\n",
    "\n",
    "# Perform matrix multiplication between C and D\n",
    "matrix_E = tf.matmul(matrix_C, matrix_D)\n",
    "\n",
    "# Display the result matrix E\n",
    "print(\"Matrix E (Result of C * D):\")\n",
    "print(matrix_E.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedd6cd-ff12-498e-91f0-5c5213ae654d",
   "metadata": {},
   "source": [
    "Task 2: Performing Additional Matrix Operationk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ac3ef-7664-44df-8341-38c71b8d2e2a",
   "metadata": {},
   "source": [
    "1. Create a matrix F with dimensions 3x3, initialized with random values using TensorFlow's random_uniform function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26e37b21-7419-4026-be74-c3ad273c438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix F:\n",
      "[[0.35843587 0.74229395 0.65148246]\n",
      " [0.31182778 0.24165595 0.69925725]\n",
      " [0.88391685 0.5967181  0.40546298]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the matrix\n",
    "matrix_shape = (3, 3)\n",
    "\n",
    "# Create matrix F with random values between 0 and 1\n",
    "matrix_F = tf.random.uniform(shape=matrix_shape, minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix F:\")\n",
    "print(matrix_F.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a672c-0040-40a1-bf6c-4a042c8f5108",
   "metadata": {},
   "source": [
    "2. Calculate the transpose of matrix F and store the result in matrix G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cd33f2e-1b09-44b5-a119-902231d40bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix F:\n",
      "[[0.1928389  0.1028955  0.8979058 ]\n",
      " [0.7349212  0.3671707  0.5931699 ]\n",
      " [0.97469175 0.31764293 0.55295503]]\n",
      "Matrix G (Transpose of F):\n",
      "[[0.1928389  0.7349212  0.97469175]\n",
      " [0.1028955  0.3671707  0.31764293]\n",
      " [0.8979058  0.5931699  0.55295503]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have matrix F as previously defined\n",
    "matrix_shape = (3, 3)\n",
    "matrix_F = tf.random.uniform(shape=matrix_shape, minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix F:\")\n",
    "print(matrix_F.numpy())\n",
    "\n",
    "# Calculate the transpose of matrix F and store it in matrix G\n",
    "matrix_G = tf.transpose(matrix_F)\n",
    "\n",
    "# Display the values of matrix G (the transpose of F)\n",
    "print(\"Matrix G (Transpose of F):\")\n",
    "print(matrix_G.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee10f72-6737-4c70-bc68-93478db25d44",
   "metadata": {},
   "source": [
    "3. Calculate the element-wise exponential of matrix F and store the result in matrix H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "098f8965-910f-4f07-83c2-7eea3e822178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix H (Element-wise Exponential of F):\n",
      "[[1.804353  1.7801867 1.2760661]\n",
      " [1.3365791 1.4984244 1.0284352]\n",
      " [2.546889  2.1808167 1.6800363]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have matrix F as previously defined\n",
    "matrix_shape = (3, 3)\n",
    "matrix_F = tf.random.uniform(shape=matrix_shape, minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "# Calculate the element-wise exponential of matrix F and store it in matrix H\n",
    "matrix_H = tf.math.exp(matrix_F)\n",
    "\n",
    "# Display the values of matrix H\n",
    "print(\"Matrix H (Element-wise Exponential of F):\")\n",
    "print(matrix_H.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f09c92-e94f-4917-91ea-1df9890ea341",
   "metadata": {},
   "source": [
    "4. Create a matrix I by concatenating matrix F and matrix G horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de2bcf97-fb43-46e3-a538-d7b7d2bc053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix F:\n",
      "[[0.41009986 0.72849715 0.5150701 ]\n",
      " [0.33113503 0.4869449  0.469409  ]\n",
      " [0.41411006 0.13836586 0.6505649 ]]\n",
      "Matrix G (Transpose of F):\n",
      "[[0.41009986 0.33113503 0.41411006]\n",
      " [0.72849715 0.4869449  0.13836586]\n",
      " [0.5150701  0.469409   0.6505649 ]]\n",
      "Matrix I (Concatenation of F and G horizontally):\n",
      "[[0.41009986 0.72849715 0.5150701  0.41009986 0.33113503 0.41411006]\n",
      " [0.33113503 0.4869449  0.469409   0.72849715 0.4869449  0.13836586]\n",
      " [0.41411006 0.13836586 0.6505649  0.5150701  0.469409   0.6505649 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have matrices F and G as previously defined\n",
    "matrix_shape = (3, 3)\n",
    "matrix_F = tf.random.uniform(shape=matrix_shape, minval=0, maxval=1, dtype=tf.float32)\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix F:\")\n",
    "print(matrix_F.numpy())\n",
    "matrix_G = tf.transpose(matrix_F)  # Transpose of F for illustration\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix G (Transpose of F):\")\n",
    "print(matrix_G.numpy())\n",
    "\n",
    "# Concatenate matrices F and G horizontally to create matrix I\n",
    "matrix_I = tf.concat([matrix_F, matrix_G], axis=1)\n",
    "\n",
    "# Display the values of matrix I\n",
    "print(\"Matrix I (Concatenation of F and G horizontally):\")\n",
    "print(matrix_I.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a1e7a-14ab-43f9-9a84-da9a7f8c601b",
   "metadata": {},
   "source": [
    "5. Create a matrix J by concatenating matrix F and matrix H vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c99ca73-6efb-463d-bb59-d95052420d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix F:\n",
      "[[0.4037652  0.92462206 0.73189807]\n",
      " [0.00100589 0.36414814 0.18294764]\n",
      " [0.63655496 0.8443724  0.5356635 ]]\n",
      "Matrix G (Transpose of F):\n",
      "[[0.4037652  0.00100589 0.63655496]\n",
      " [0.92462206 0.36414814 0.8443724 ]\n",
      " [0.73189807 0.18294764 0.5356635 ]]\n",
      "Matrix I (Concatenation of F and G vertically):\n",
      "[[0.4037652  0.92462206 0.73189807]\n",
      " [0.00100589 0.36414814 0.18294764]\n",
      " [0.63655496 0.8443724  0.5356635 ]\n",
      " [0.4037652  0.00100589 0.63655496]\n",
      " [0.92462206 0.36414814 0.8443724 ]\n",
      " [0.73189807 0.18294764 0.5356635 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have matrices F and G as previously defined\n",
    "matrix_shape = (3, 3)\n",
    "matrix_F = tf.random.uniform(shape=matrix_shape, minval=0, maxval=1, dtype=tf.float32)\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix F:\")\n",
    "print(matrix_F.numpy())\n",
    "matrix_G = tf.transpose(matrix_F)  # Transpose of F for illustration\n",
    "# Display the values of matrix F\n",
    "print(\"Matrix G (Transpose of F):\")\n",
    "print(matrix_G.numpy())\n",
    "\n",
    "# Concatenate matrices F and G horizontally to create matrix I\n",
    "matrix_I = tf.concat([matrix_F, matrix_G], axis=0)\n",
    "\n",
    "# Display the values of matrix I\n",
    "print(\"Matrix I (Concatenation of F and G vertically):\")\n",
    "print(matrix_I.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
